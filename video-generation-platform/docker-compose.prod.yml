version: "3.8"

services:
  # Backend API Service - Production
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
      target: runtime
      args:
        - NODE_ENV=production
        - BUILD_NUMBER=${BUILD_NUMBER:-latest}
    image: video-generation-backend:${IMAGE_TAG:-latest}
    container_name: video-generation-backend-prod
    ports:
      - "127.0.0.1:3000:3000"
    environment:
      - NODE_ENV=production
      - PORT=3000
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY}
      - SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
      - AWS_REGION=${AWS_REGION}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_S3_BUCKET=${AWS_S3_BUCKET}
      - FFMPEG_PATH=/usr/bin/ffmpeg
      - FFPROBE_PATH=/usr/bin/ffprobe
      - TEMP_DIR=/tmp/video-processing
      - IMMEDIATE_RESPONSE_THRESHOLD=${IMMEDIATE_RESPONSE_THRESHOLD:-30000}
      - MAX_CONCURRENT_JOBS=${MAX_CONCURRENT_JOBS:-10}
      - CORS_ORIGINS=${CORS_ORIGINS}
      - REDIS_URL=redis://redis:6379
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - JWT_SECRET=${JWT_SECRET}
      - RATE_LIMIT_WINDOW_MS=${RATE_LIMIT_WINDOW_MS:-60000}
      - RATE_LIMIT_MAX_REQUESTS=${RATE_LIMIT_MAX_REQUESTS:-60}
      - SESSION_SECRET=${SESSION_SECRET}
      - WEBHOOK_SECRET=${WEBHOOK_SECRET}
      - SENTRY_DSN=${SENTRY_DSN}
      - NEW_RELIC_LICENSE_KEY=${NEW_RELIC_LICENSE_KEY}
      - DATADOG_API_KEY=${DATADOG_API_KEY}
    volumes:
      - backend-temp:/tmp/video-processing
      - backend-logs:/app/logs
      - backend-uploads:/app/uploads
      - /etc/ssl/certs:/etc/ssl/certs:ro
    depends_on:
      redis:
        condition: service_healthy
      database:
        condition: service_healthy
    networks:
      - video-generation-internal
      - video-generation-external
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 60s
    deploy:
      replicas: ${BACKEND_REPLICAS:-2}
      resources:
        limits:
          cpus: "${BACKEND_CPU_LIMIT:-4.0}"
          memory: ${BACKEND_MEMORY_LIMIT:-2G}
        reservations:
          cpus: "${BACKEND_CPU_RESERVATION:-1.0}"
          memory: ${BACKEND_MEMORY_RESERVATION:-1G}
      placement:
        constraints:
          - node.role == worker
      update_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        order: start-first
      rollback_config:
        parallelism: 1
        delay: 30s
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
        window: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service,environment"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.backend.rule=Host(`api.${DOMAIN}`)"
      - "traefik.http.routers.backend.entrypoints=websecure"
      - "traefik.http.routers.backend.tls.certresolver=letsencrypt"
      - "traefik.http.services.backend.loadbalancer.server.port=3000"
      - "traefik.http.services.backend.loadbalancer.healthcheck.path=/health"

  # Frontend Service - Production
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: runtime
      args:
        - VITE_API_BASE_URL=${VITE_API_BASE_URL}
        - VITE_SUPABASE_URL=${VITE_SUPABASE_URL}
        - VITE_SUPABASE_ANON_KEY=${VITE_SUPABASE_ANON_KEY}
        - VITE_AWS_S3_BUCKET=${VITE_AWS_S3_BUCKET}
        - VITE_APP_VERSION=${BUILD_NUMBER:-latest}
        - BUILD_NUMBER=${BUILD_NUMBER:-latest}
    image: video-generation-frontend:${IMAGE_TAG:-latest}
    container_name: video-generation-frontend-prod
    ports:
      - "127.0.0.1:80:80"
      - "127.0.0.1:443:443"
    environment:
      - NGINX_WORKER_PROCESSES=${NGINX_WORKER_PROCESSES:-auto}
      - NGINX_WORKER_CONNECTIONS=${NGINX_WORKER_CONNECTIONS:-1024}
      - NGINX_KEEPALIVE_TIMEOUT=${NGINX_KEEPALIVE_TIMEOUT:-65}
    volumes:
      - ./ssl:/etc/ssl/certs:ro
      - frontend-cache:/var/cache/nginx
      - frontend-logs:/var/log/nginx
    depends_on:
      - backend
    networks:
      - video-generation-external
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 45s
    deploy:
      replicas: ${FRONTEND_REPLICAS:-2}
      resources:
        limits:
          cpus: "${FRONTEND_CPU_LIMIT:-1.0}"
          memory: ${FRONTEND_MEMORY_LIMIT:-512M}
        reservations:
          cpus: "${FRONTEND_CPU_RESERVATION:-0.25}"
          memory: ${FRONTEND_MEMORY_RESERVATION:-128M}
      placement:
        constraints:
          - node.role == worker
      update_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        order: start-first
      rollback_config:
        parallelism: 1
        delay: 30s
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service,environment"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.frontend.rule=Host(`${DOMAIN}`)"
      - "traefik.http.routers.frontend.entrypoints=websecure"
      - "traefik.http.routers.frontend.tls.certresolver=letsencrypt"
      - "traefik.http.services.frontend.loadbalancer.server.port=80"
      - "traefik.http.services.frontend.loadbalancer.healthcheck.path=/health"

  # Orchestrator Service - Production
  orchestrator:
    build:
      context: ./orchestrator
      dockerfile: Dockerfile
      target: runtime
      args:
        - NODE_ENV=production
        - BUILD_NUMBER=${BUILD_NUMBER:-latest}
    image: video-generation-orchestrator:${IMAGE_TAG:-latest}
    container_name: video-generation-orchestrator-prod
    ports:
      - "127.0.0.1:9000:9000"
    environment:
      - NODE_ENV=production
      - PORT=9000
      - BACKEND_URL=http://backend:3000
      - REDIS_URL=redis://redis:6379
      - MAX_CONCURRENT_JOBS=${ORCHESTRATOR_MAX_CONCURRENT_JOBS:-20}
      - JOB_TIMEOUT=${ORCHESTRATOR_JOB_TIMEOUT:-1800000}
      - HEALTH_CHECK_INTERVAL=${ORCHESTRATOR_HEALTH_CHECK_INTERVAL:-30000}
      - QUEUE_RETRY_ATTEMPTS=${QUEUE_RETRY_ATTEMPTS:-5}
      - QUEUE_RETRY_DELAY=${QUEUE_RETRY_DELAY:-10000}
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - SENTRY_DSN=${SENTRY_DSN}
      - NEW_RELIC_LICENSE_KEY=${NEW_RELIC_LICENSE_KEY}
    volumes:
      - orchestrator-logs:/app/logs
      - orchestrator-temp:/app/temp
      - orchestrator-queue:/app/queue-data
    depends_on:
      backend:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - video-generation-internal
      - video-generation-external
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/health"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 60s
    deploy:
      replicas: ${ORCHESTRATOR_REPLICAS:-2}
      resources:
        limits:
          cpus: "${ORCHESTRATOR_CPU_LIMIT:-3.0}"
          memory: ${ORCHESTRATOR_MEMORY_LIMIT:-1.5G}
        reservations:
          cpus: "${ORCHESTRATOR_CPU_RESERVATION:-0.5}"
          memory: ${ORCHESTRATOR_MEMORY_RESERVATION:-512M}
      placement:
        constraints:
          - node.role == worker
      update_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        order: start-first
      rollback_config:
        parallelism: 1
        delay: 30s
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
        window: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service,environment"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.orchestrator.rule=Host(`orchestrator.${DOMAIN}`)"
      - "traefik.http.routers.orchestrator.entrypoints=websecure"
      - "traefik.http.routers.orchestrator.tls.certresolver=letsencrypt"
      - "traefik.http.services.orchestrator.loadbalancer.server.port=9000"

  # Redis for job queuing and caching - Production
  redis:
    image: redis:7-alpine
    container_name: video-generation-redis-prod
    ports:
      - "127.0.0.1:6379:6379"
    environment:
      - REDIS_APPENDONLY=yes
      - REDIS_APPENDFSYNC=everysec
      - REDIS_MAXMEMORY=${REDIS_MAXMEMORY:-2gb}
      - REDIS_MAXMEMORY_POLICY=allkeys-lru
    volumes:
      - redis-data:/data
      - ./redis/redis.prod.conf:/usr/local/etc/redis/redis.conf:ro
      - redis-logs:/var/log/redis
    command: >
      redis-server /usr/local/etc/redis/redis.conf
      --requirepass ${REDIS_PASSWORD}
      --maxmemory ${REDIS_MAXMEMORY:-2gb}
      --maxmemory-policy allkeys-lru
      --appendonly yes
      --appendfsync everysec
    networks:
      - video-generation-internal
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: "${REDIS_CPU_LIMIT:-1.0}"
          memory: ${REDIS_MEMORY_LIMIT:-2.5G}
        reservations:
          cpus: "${REDIS_CPU_RESERVATION:-0.25}"
          memory: ${REDIS_MEMORY_RESERVATION:-1G}
      placement:
        constraints:
          - node.role == worker
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # PostgreSQL Database - Production
  database:
    image: postgres:15-alpine
    container_name: video-generation-db-prod
    ports:
      - "127.0.0.1:5432:5432"
    environment:
      - POSTGRES_DB=${DB_NAME}
      - POSTGRES_USER=${DB_USER}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=C --lc-ctype=C
      - PGDATA=/var/lib/postgresql/data/pgdata
      - POSTGRES_SHARED_PRELOAD_LIBRARIES=pg_stat_statements
      - POSTGRES_MAX_CONNECTIONS=${DB_MAX_CONNECTIONS:-200}
      - POSTGRES_SHARED_BUFFERS=${DB_SHARED_BUFFERS:-256MB}
      - POSTGRES_EFFECTIVE_CACHE_SIZE=${DB_EFFECTIVE_CACHE_SIZE:-1GB}
      - POSTGRES_MAINTENANCE_WORK_MEM=${DB_MAINTENANCE_WORK_MEM:-64MB}
      - POSTGRES_CHECKPOINT_COMPLETION_TARGET=${DB_CHECKPOINT_COMPLETION_TARGET:-0.9}
      - POSTGRES_WAL_BUFFERS=${DB_WAL_BUFFERS:-16MB}
      - POSTGRES_DEFAULT_STATISTICS_TARGET=${DB_DEFAULT_STATISTICS_TARGET:-100}
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - postgres-backups:/backups
      - ./database/init:/docker-entrypoint-initdb.d:ro
      - ./database/migrations:/migrations:ro
      - ./database/postgresql.prod.conf:/etc/postgresql/postgresql.conf:ro
    command: >
      postgres
      -c config_file=/etc/postgresql/postgresql.conf
      -c shared_preload_libraries=pg_stat_statements
      -c log_statement=all
      -c log_min_duration_statement=1000
      -c log_line_prefix='%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
    networks:
      - video-generation-internal
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${DB_NAME}"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 60s
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: "${DB_CPU_LIMIT:-2.0}"
          memory: ${DB_MEMORY_LIMIT:-2G}
        reservations:
          cpus: "${DB_CPU_RESERVATION:-0.5}"
          memory: ${DB_MEMORY_RESERVATION:-512M}
      placement:
        constraints:
          - node.role == worker
          - node.labels.database == true
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
        window: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # Traefik Load Balancer and SSL Termination
  traefik:
    image: traefik:v3.0
    container_name: video-generation-traefik-prod
    ports:
      - "80:80"
      - "443:443"
      - "127.0.0.1:8080:8080"
    environment:
      - TRAEFIK_API_DASHBOARD=true
      - TRAEFIK_API_INSECURE=false
      - TRAEFIK_ENTRYPOINTS_WEB_ADDRESS=:80
      - TRAEFIK_ENTRYPOINTS_WEBSECURE_ADDRESS=:443
      - TRAEFIK_CERTIFICATESRESOLVERS_LETSENCRYPT_ACME_HTTPCHALLENGE=true
      - TRAEFIK_CERTIFICATESRESOLVERS_LETSENCRYPT_ACME_HTTPCHALLENGE_ENTRYPOINT=web
      - TRAEFIK_CERTIFICATESRESOLVERS_LETSENCRYPT_ACME_EMAIL=${ACME_EMAIL}
      - TRAEFIK_CERTIFICATESRESOLVERS_LETSENCRYPT_ACME_STORAGE=/letsencrypt/acme.json
      - TRAEFIK_PROVIDERS_DOCKER=true
      - TRAEFIK_PROVIDERS_DOCKER_EXPOSEDBYDEFAULT=false
      - TRAEFIK_PROVIDERS_DOCKER_NETWORK=video-generation-external
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - traefik-letsencrypt:/letsencrypt
      - ./traefik/traefik.prod.yml:/etc/traefik/traefik.yml:ro
      - ./traefik/dynamic:/etc/traefik/dynamic:ro
    networks:
      - video-generation-external
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "traefik", "healthcheck"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: "0.5"
          memory: 256M
        reservations:
          cpus: "0.1"
          memory: 64M
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 60s
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.traefik.rule=Host(`traefik.${DOMAIN}`)"
      - "traefik.http.routers.traefik.entrypoints=websecure"
      - "traefik.http.routers.traefik.tls.certresolver=letsencrypt"
      - "traefik.http.routers.traefik.service=api@internal"
      - "traefik.http.routers.traefik.middlewares=auth"
      - "traefik.http.middlewares.auth.basicauth.users=${TRAEFIK_AUTH}"

  # Prometheus for metrics collection - Production
  prometheus:
    image: prom/prometheus:v2.45.0
    container_name: video-generation-prometheus-prod
    ports:
      - "127.0.0.1:9090:9090"
    environment:
      - TZ=UTC
    volumes:
      - ./monitoring/prometheus/prometheus.prod.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/prometheus/rules:/etc/prometheus/rules:ro
      - ./monitoring/prometheus/alerts:/etc/prometheus/alerts:ro
      - prometheus-data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/etc/prometheus/console_libraries"
      - "--web.console.templates=/etc/prometheus/consoles"
      - "--storage.tsdb.retention.time=${PROMETHEUS_RETENTION_TIME:-30d}"
      - "--storage.tsdb.retention.size=${PROMETHEUS_RETENTION_SIZE:-10GB}"
      - "--web.enable-lifecycle"
      - "--web.enable-admin-api"
      - "--log.level=info"
      - "--web.external-url=https://prometheus.${DOMAIN}"
    networks:
      - video-generation-internal
      - video-generation-external
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: "${PROMETHEUS_CPU_LIMIT:-2.0}"
          memory: ${PROMETHEUS_MEMORY_LIMIT:-2G}
        reservations:
          cpus: "${PROMETHEUS_CPU_RESERVATION:-0.5}"
          memory: ${PROMETHEUS_MEMORY_RESERVATION:-512M}
      placement:
        constraints:
          - node.role == worker
          - node.labels.monitoring == true
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
        window: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.prometheus.rule=Host(`prometheus.${DOMAIN}`)"
      - "traefik.http.routers.prometheus.entrypoints=websecure"
      - "traefik.http.routers.prometheus.tls.certresolver=letsencrypt"
      - "traefik.http.services.prometheus.loadbalancer.server.port=9090"
      - "traefik.http.routers.prometheus.middlewares=auth"

  # Grafana for visualization - Production
  grafana:
    image: grafana/grafana:10.0.0
    container_name: video-generation-grafana-prod
    ports:
      - "127.0.0.1:3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-piechart-panel,grafana-clock-panel,grafana-polystat-panel
      - GF_FEATURE_TOGGLES_ENABLE=ngalert
      - GF_LOG_LEVEL=info
      - GF_SMTP_ENABLED=${GRAFANA_SMTP_ENABLED:-false}
      - GF_SMTP_HOST=${GRAFANA_SMTP_HOST}
      - GF_SMTP_USER=${GRAFANA_SMTP_USER}
      - GF_SMTP_PASSWORD=${GRAFANA_SMTP_PASSWORD}
      - GF_SMTP_FROM_ADDRESS=${GRAFANA_SMTP_FROM_ADDRESS}
      - GF_SERVER_ROOT_URL=https://grafana.${DOMAIN}
      - GF_DATABASE_TYPE=postgres
      - GF_DATABASE_HOST=database:5432
      - GF_DATABASE_NAME=${DB_NAME}
      - GF_DATABASE_USER=${DB_USER}
      - GF_DATABASE_PASSWORD=${DB_PASSWORD}
      - GF_DATABASE_SSL_MODE=require
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
      - ./monitoring/grafana/alerting:/etc/grafana/provisioning/alerting:ro
      - ./monitoring/grafana/plugins:/var/lib/grafana/plugins:ro
    depends_on:
      - prometheus
      - database
    networks:
      - video-generation-internal
      - video-generation-external
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: "${GRAFANA_CPU_LIMIT:-1.0}"
          memory: ${GRAFANA_MEMORY_LIMIT:-512M}
        reservations:
          cpus: "${GRAFANA_CPU_RESERVATION:-0.25}"
          memory: ${GRAFANA_MEMORY_RESERVATION:-128M}
      placement:
        constraints:
          - node.role == worker
          - node.labels.monitoring == true
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
        window: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.grafana.rule=Host(`grafana.${DOMAIN}`)"
      - "traefik.http.routers.grafana.entrypoints=websecure"
      - "traefik.http.routers.grafana.tls.certresolver=letsencrypt"
      - "traefik.http.services.grafana.loadbalancer.server.port=3000"

  # Node Exporter for system metrics
  node-exporter:
    image: prom/node-exporter:v1.6.0
    container_name: video-generation-node-exporter-prod
    ports:
      - "127.0.0.1:9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - video-generation-internal
    restart: unless-stopped
    deploy:
      mode: global
      resources:
        limits:
          cpus: "0.25"
          memory: 64M
        reservations:
          cpus: "0.1"
          memory: 32M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3

  # Cadvisor for container metrics
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.0
    container_name: video-generation-cadvisor-prod
    ports:
      - "127.0.0.1:8082:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    privileged: true
    devices:
      - /dev/kmsg:/dev/kmsg
    networks:
      - video-generation-internal
    restart: unless-stopped
    deploy:
      mode: global
      resources:
        limits:
          cpus: "0.5"
          memory: 256M
        reservations:
          cpus: "0.1"
          memory: 128M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3

  # Database backup service
  db-backup:
    image: prodrigestivill/postgres-backup-local:15
    container_name: video-generation-db-backup-prod
    environment:
      - POSTGRES_HOST=database
      - POSTGRES_DB=${DB_NAME}
      - POSTGRES_USER=${DB_USER}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_EXTRA_OPTS=-Z9 --schema=public --blobs
      - SCHEDULE=${BACKUP_SCHEDULE:-@daily}
      - BACKUP_KEEP_DAYS=${BACKUP_KEEP_DAYS:-7}
      - BACKUP_KEEP_WEEKS=${BACKUP_KEEP_WEEKS:-4}
      - BACKUP_KEEP_MONTHS=${BACKUP_KEEP_MONTHS:-6}
    volumes:
      - postgres-backups:/backups
    depends_on:
      - database
    networks:
      - video-generation-internal
    restart: unless-stopped
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: "0.5"
          memory: 256M
        reservations:
          cpus: "0.1"
          memory: 64M
      placement:
        constraints:
          - node.labels.backup == true
      restart_policy:
        condition: on-failure
        delay: 30s
        max_attempts: 3
        window: 300s

  # Log aggregation with Loki
  loki:
    image: grafana/loki:2.8.0
    container_name: video-generation-loki-prod
    ports:
      - "127.0.0.1:3100:3100"
    volumes:
      - ./monitoring/loki/loki.prod.yml:/etc/loki/local-config.yaml:ro
      - loki-data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - video-generation-internal
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: "1.0"
          memory: 512M
        reservations:
          cpus: "0.25"
          memory: 128M
      placement:
        constraints:
          - node.labels.logging == true
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3

  # Log shipping with Promtail
  promtail:
    image: grafana/promtail:2.8.0
    container_name: video-generation-promtail-prod
    volumes:
      - ./monitoring/promtail/promtail.prod.yml:/etc/promtail/config.yml:ro
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    command: -config.file=/etc/promtail/config.yml
    depends_on:
      - loki
    networks:
      - video-generation-internal
    restart: unless-stopped
    deploy:
      mode: global
      resources:
        limits:
          cpus: "0.25"
          memory: 128M
        reservations:
          cpus: "0.1"
          memory: 64
